{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "Welcome to `lingcorpora`'s documentation. In order to get started, see [Installation](#Installation) and then proceed to [Quickstart](#Quickstart). For parameter description, see [Making queries](#Making-queries). To obtain description of our `Target` and `Result` objects, go to [Working with results](#Working-with-results).\n",
    "\n",
    "* [Installation](#Installation)\n",
    "* [Quickstart](#Quickstart)\n",
    "* [Making queries](#Making-queries)\n",
    "  * [lingcorpora.Corpus](#lingcorpora.Corpus)\n",
    "  * [Corpora](#Corpora)\n",
    "* [Working with results](#Working-with-results)\n",
    "  * [lingcorpora.Target](#lingcorpora.Target)\n",
    "  * [lingcorpora.Result](#lingcorpora.Result)\n",
    "\n",
    "## Installation\n",
    "\n",
    "To install `lingcorpora`, type in the terminal:\n",
    "```\n",
    "pip install lingcorpora\n",
    "```\n",
    "lingcorpora has dependencies on:\n",
    "* [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)\n",
    "* [lxml](http://lxml.de)\n",
    "* [requests](http://docs.python-requests.org/en/master/)\n",
    "* [tqdm](https://github.com/tqdm/tqdm)\n",
    "\n",
    "`lingcorpora` will install these packages during installation. If you have troubles with installing dependencies, check Installation section in the documentation of the according packages.\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "To search in any corpus, you need to create an instance of `Corpus` object and use method `search`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"мешок\": 100%|██████████| 10/10 [00:01<00:00,  8.10docs/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Result(query=мешок, N=10, params={'n_results': 10, 'kwic': True, 'n_left': None, 'n_right': None, 'query_language': None, 'subcorpus': 'main', 'get_analysis': False, 'gr_tags': None, 'start': 0, 'writing_system': None})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lingcorpora import Corpus\n",
    "rus_corp = Corpus('rus')\n",
    "rus_results = rus_corp.search('мешок', n_results = 10)\n",
    "rus_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results are stored in the `Result` object. `Result` is the list of `Target` objects. To print the data, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  [lafet, nick]   «Считают, что если они кому-нибудь отсыпят мешок золота, то можно всех пригласить? \n",
      "2  [Hamlet, nick]   ещё добрые преподы, которым просто некогда, и которые за мешок с пивом лихо ставили не самые плохие оценки всей группе ^ Но, но, но… \n",
      "3  ))) И мешок для сменки Немо, и рюкзак, и пеналы-ручки-тетрадки. \n",
      "4  Можешь использовать мешок многократно, простирывая после каждой варки с мылом, но только не в стиральном порошке. \n",
      "5  И этот мешок ― как скатерть-самобранка; в нём всё прибывает орехов. \n",
      "6  Наверняка пойдёт на дно, как мешок с песком!\" \n",
      "7   Капитан-шеф-повар побежал было на нос, чтобы увести Эле-Фантика Но как раз в этот миг налетел девятый вал и, подстегиваемый ураганом, рухнул, как девятиэтажный дом, точно на слонёнка - ослепил, оглушил, закрутил в водовороте и снёс за борт, как большой мешок с песком. \n",
      "8   8. 39. Древнегреческий учёный Аристотель для доказательства невесомости воздуха взвешивал пустой кожаный мешок и тот же мешок, наполненный воздухом. \n",
      "9   8. 39. Древнегреческий учёный Аристотель для доказательства невесомости воздуха взвешивал пустой кожаный мешок и тот же мешок, наполненный воздухом. \n",
      "10   8. 39. Потому что вес мешка с воздухом увеличивался на столько, на сколько увеличивалась выталкивающая сила, действующая со стороны воздуха на раздутый мешок. \n"
     ]
    }
   ],
   "source": [
    "for result in rus_results:\n",
    "    for i,target in enumerate(result):\n",
    "        print(i+1, target.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output can be transformed to `kwic` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 что если они кому-нибудь отсыпят\tмешок\tзолота, то можно всех пригласить?\n",
      "2 просто некогда, и которые за\tмешок\tс пивом лихо ставили не\n",
      "3 ))) И\tмешок\tдля сменки Немо, и рюкзак,\n",
      "4 Можешь использовать\tмешок\tмногократно, простирывая после каждой варки\n",
      "5 И этот\tмешок\t― как скатерть-самобранка; в нём\n",
      "6 Наверняка пойдёт на дно, как\tмешок\tс песком!\"\n",
      "7 снёс за борт, как большой\tмешок\tс песком.\n",
      "8 невесомости воздуха взвешивал пустой кожаный\tмешок\tи тот же мешок, наполненный\n",
      "9 кожаный мешок и тот же\tмешок\t, наполненный воздухом.\n",
      "10 со стороны воздуха на раздутый\tмешок\t.\n"
     ]
    }
   ],
   "source": [
    "for result in rus_results:\n",
    "    for i,target in enumerate(result):\n",
    "        print(i+1,'\\t'.join(target.kwic(left=5,right=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can search by multiple queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"сумка\": 100%|██████████| 10/10 [00:05<00:00,  1.77docs/s]\n",
      "\"мешок\": 100%|██████████| 10/10 [00:06<00:00,  1.54docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  При этом у меня ещё была тяжеленная сумка и чужой дорогой фотоаппарат.. \n",
      "2  И вдруг увидела, что её сумка разрезана. \n",
      "3  Господин Эрмес-Дюма мягко намекнул Джейн, что её сумка для ручной клади ― эта была плетёная корзинка в стиле \"воронье гнездо\" ― выглядит как-то… ну, неподобающим для известной актрисы образом. \n",
      "4  Простая на первый взгляд, классическая сумка стоит от $ 6 тысяч (хм, мог бы получиться неплохой автомобиль!), а чтобы её купить, нужно ждать от шести месяцев до двух лет, встав на waitlist! \n",
      "5  За что сумка Birkin такая дорогая и отчего каждые девять секунд в мире кто-нибудь покупает платок-каре от Hermes? \n",
      "6  Кроме того что эту сумочку обожала принцесса Грейс Келли и везде с ней появлялась, смотреть там особо не на что: простая классическая кожаная сумка, стоит при этом $ 12 тысяч (хм, мог бы получиться неплохой автомобиль!), а чтобы стать её обладательницей, нужно ждать минимум два года, встав на wait- list― и в очередь ещё не всех берут! \n",
      "7   Новая сумка Dado из телячьей кожи ― несмотря на свои мягкие очертания, сумка не потеряет формы благодаря особой технологии \n",
      "8   Новая сумка Dado из телячьей кожи ― несмотря на свои мягкие очертания, сумка не потеряет формы благодаря особой технологии \n",
      "9  Спина у него была всего одна, и на ней уже громоздился вещмешок с толом и гранатами, плечо давила увесистая санитарная сумка, в руках он держал винтовку. \n",
      "10  Санитарная сумка немного давила его плечо, но уж как-нибудь он её донесёт. \n",
      "\n",
      "1  [lafet, nick]   «Считают, что если они кому-нибудь отсыпят мешок золота, то можно всех пригласить? \n",
      "2  [Hamlet, nick]   ещё добрые преподы, которым просто некогда, и которые за мешок с пивом лихо ставили не самые плохие оценки всей группе ^ Но, но, но… \n",
      "3  ))) И мешок для сменки Немо, и рюкзак, и пеналы-ручки-тетрадки. \n",
      "4  Можешь использовать мешок многократно, простирывая после каждой варки с мылом, но только не в стиральном порошке. \n",
      "5  И этот мешок ― как скатерть-самобранка; в нём всё прибывает орехов. \n",
      "6  Наверняка пойдёт на дно, как мешок с песком!\" \n",
      "7   Капитан-шеф-повар побежал было на нос, чтобы увести Эле-Фантика Но как раз в этот миг налетел девятый вал и, подстегиваемый ураганом, рухнул, как девятиэтажный дом, точно на слонёнка - ослепил, оглушил, закрутил в водовороте и снёс за борт, как большой мешок с песком. \n",
      "8   8. 39. Древнегреческий учёный Аристотель для доказательства невесомости воздуха взвешивал пустой кожаный мешок и тот же мешок, наполненный воздухом. \n",
      "9   8. 39. Древнегреческий учёный Аристотель для доказательства невесомости воздуха взвешивал пустой кожаный мешок и тот же мешок, наполненный воздухом. \n",
      "10   8. 39. Потому что вес мешка с воздухом увеличивался на столько, на сколько увеличивалась выталкивающая сила, действующая со стороны воздуха на раздутый мешок. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rus_results = rus_corp.search(['сумка','мешок'], n_results = 10)\n",
    "for result in rus_results:\n",
    "    for i,target in enumerate(result):\n",
    "        print(i+1,target.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To the top](#Documentation)\n",
    "\n",
    "## Making queries\n",
    " \n",
    "\n",
    "### lingcorpora.Corpus\n",
    "\n",
    "lingcorpora.Corpus(language, sleep_time=1, sleep_each=5)<br>\n",
    "The object of this class should be instantiated for each corpus. Search is conducted via `search` method.\n",
    "\n",
    "#### Attributes\n",
    "* **language**: str: in most cases, language [ISO 639-3 code](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) for the corpus with combined codes for parallel corpora. List of available corpora with corresponding codes:\n",
    "\n",
    "| Code         | Corpus                                                                        |\n",
    "|--------------|-------------------------------------------------------------------------------|\n",
    "| bam          | [Corpus Bambara de Reference](#Corpus-Bambara-de-Reference)                   |\n",
    "| emk          | [Maninka Automatically Parsed corpus](#Maninka-Automatically-Parsed-corpus)   |\n",
    "| rus          | [National Corpus of Russian Language](#National-Corpus-of-Russian-Language)   |\n",
    "| rus_parallel | [Parallel subcorpus of National Corpus of Russian Language](#Parallel-subcorpus-of-National-Corpus-of-Russian-Language) |\n",
    "| zho          | [Center of Chinese Linguistics corpus](#Center-of-Chinese-Linguistics-corpus) |\n",
    "\n",
    "* **sleep_time**: int, optional, default 1: the length of pause between requests to the corpus (in seconds). It is required to avoid blocking and corpus breakdown.\n",
    "* **sleep_each**: int, optional, default 5: the number of requests after which a pause is required.\n",
    "* **doc**: str: documentation for chosen corpus (after instance creation).\n",
    "* **results**: list: list of all `Result` objects, each returned by `search` method.\n",
    "* **failed**: list: list of `Result` objects where nothing was found.\n",
    "\n",
    "#### lingcorpora.Corpus.search(query, \\*args, \\*\\*kwargs)\n",
    "\n",
    "This is a search function that queries the corpus and returns the results.\n",
    "\n",
    "##### Arguments\n",
    "\n",
    "Here we provide a comprehensive list of arguments, although not all arguments are applicable to all corpora and the default values depend on a corpus. For specific description, go to [Corpora](#Corpora) subsection.\n",
    "\n",
    "Two arguments are universal:\n",
    "\n",
    "* **query**: str or list[str]: query or queries\n",
    "* **n_results**: int, optional, default 100: number of results wanted\n",
    "\n",
    "Other depend on the corpus:\n",
    "\n",
    "* **kwic**: boolean, optional, default True: `kwic` format (True) or a sentence (False)\n",
    "* **n_left**: int, optional: number of words / symbols (corpus-specific) in the left context\n",
    "* **n_right**: int, optional: number of words / symbols (corpus-specific) in the right context\n",
    "* **query_language**: str: for parallel corpora, language of the query\n",
    "* **subcorpus**: str, optional: subcorpus to search in\n",
    "* **get_analysis**: boolean, optional, default False: whether to download grammatical information if the corpus is annotated\n",
    "* **writing_system**: str, optional: writing system of results\n",
    " \n",
    "\n",
    "##### Output\n",
    "\n",
    "* **Result**: list: resuls for queries in current search\n",
    "\n",
    "`search` returns the result of current query and adds it to `results` attribute of corresponding `Corpus` object. In the following example, `first_result` and `second_result` contain results of two queries (the second consists of two `Result` objects), whereas `bam_corp.results` contains all results obtained from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"jamana\": 100%|██████████| 10/10 [00:00<00:00, 34.44docs/s]\n",
      "\"kuma\":   0%|          | 0/10 [00:00<?, ?docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result(query=jamana, N=10, params={'n_results': 10, 'kwic': True, 'n_left': None, 'n_right': None, 'query_language': None, 'subcorpus': 'corbama-net-non-tonal', 'get_analysis': False, 'gr_tags': None, 'start': 0, 'writing_system': None})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"kuma\": 100%|██████████| 10/10 [00:00<00:00, 42.26docs/s]\n",
      "\"fɔra\": 100%|██████████| 10/10 [00:00<00:00, 36.73docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result(query=kuma, N=10, params={'n_results': 10, 'kwic': True, 'n_left': None, 'n_right': None, 'query_language': None, 'subcorpus': 'corbama-net-non-tonal', 'get_analysis': False, 'gr_tags': None, 'start': 0, 'writing_system': None}), Result(query=fɔra, N=10, params={'n_results': 10, 'kwic': True, 'n_left': None, 'n_right': None, 'query_language': None, 'subcorpus': 'corbama-net-non-tonal', 'get_analysis': False, 'gr_tags': None, 'start': 0, 'writing_system': None})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bam_corp = Corpus('bam')\n",
    "\n",
    "first_result = bam_corp.search('jamana', n_results = 10)\n",
    "print(first_result)\n",
    "first_result.clear()\n",
    "second_result = bam_corp.search(['kuma','fɔra'], n_results = 10)\n",
    "print(second_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(query=jamana, N=10, params={'n_results': 10, 'kwic': True, 'n_left': None, 'n_right': None, 'query_language': None, 'subcorpus': 'corbama-net-non-tonal', 'get_analysis': False, 'gr_tags': None, 'start': 0, 'writing_system': None}),\n",
       " Result(query=kuma, N=10, params={'n_results': 10, 'kwic': True, 'n_left': None, 'n_right': None, 'query_language': None, 'subcorpus': 'corbama-net-non-tonal', 'get_analysis': False, 'gr_tags': None, 'start': 0, 'writing_system': None}),\n",
       " Result(query=fɔra, N=10, params={'n_results': 10, 'kwic': True, 'n_left': None, 'n_right': None, 'query_language': None, 'subcorpus': 'corbama-net-non-tonal', 'get_analysis': False, 'gr_tags': None, 'start': 0, 'writing_system': None})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam_corp.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lingcorpora.Corpus.retry_failed()\n",
    "\n",
    "This function redoes queries that returned empty results.\n",
    "\n",
    "##### Arguments\n",
    "There are no arguments, failed queries are taken from `failed` attribute of the `Corpus` instance.\n",
    "\n",
    "##### Output\n",
    "List of `Result` objects for which the second try was successful. It also appends successful results to the `results` attribute of the `Corpus` instance and rewrites `failed` attribute with queries that remained unsuccessful.\n",
    "\n",
    "[To the top](#Documentation)\n",
    "\n",
    "### Corpora\n",
    "\n",
    "#### [Corpus Bambara de Reference](http://maslinsky.spb.ru/bonito/run.cgi/first_form)\n",
    "##### Relevant parameters\n",
    "* **query**: str or list[str]: query or queries (currently only exact search by word or phrase is available)\n",
    "* **n_results**: int, default 100: number of results wanted\n",
    "* **kwic**: boolean, default True: `kwic` format (True) or a sentence (False)\n",
    "* **get_analysis**: boolean, default False: whether to collect grammatical tags for target word or not (available only for `corbama-net-non-tonal` subcorpus)\n",
    "* **subcorpus**: str, default `corbama-net-non-tonal`: subcorpus. Available options: `corbama-net-non-tonal`, `corbama-net-tonal`, `corbama-brut`\n",
    "\n",
    "##### Example of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"kɔ́nɔ\": 100%|██████████| 10/10 [00:00<00:00, 18.33docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 dɔ́ yé . à fɔra kó mɔ̀gɔ sí kànâ táa kúngo kɔ́nɔ sélidonya fɛ̀ . àlê y' í túgu kà táa . à\n",
      "2 fɛ̀ . àlê y' í túgu kà táa . à sélen kúngo kɔ́nɔ , à y' à sɔ̀rɔ warabilenw bɛ́ tulonkɛ lá . ù\n",
      "3 kunin fɔɲi-fɔɲi » . npogotiginin seginna dùgu kɔ́nɔ , k' ò ɲɛ́fɔ à bá yé . kàbini à ye dɔ̀nkili\n",
      "4 kà kɛ́ wárabilen yé , kà táa kúngo kɔ́nɔ . ò kɔ́ , dùgu denmisɛnw bɛ́ɛ ye dɔ̀nkili ìn\n",
      "5 kà kɛ́ warabilenw yé , kà táa kúngo kɔ́nɔ . Dugumɔgɔw bɛ́ɛ yɛlɛmana kà kɛ́ warabilenw\n",
      "6 ma sɔ̀n kà à dá . jùla dɔw tɛ̀mɛntɔ dùgu ìn kɔ́nɔ , ù kabakoyara kà mùsokɔrɔba ìn kélen\n",
      "7 » mùsokɔrɔba kó , kó dénnin dɔ́ taara kúngo kɔ́nɔ sélidonya fɛ̀ . à ye warabilenw sɔ̀rɔ tulonkɛ\n",
      "8 lá . kàbini dénnin ìn seginna dùgu kɔ́nɔ kà sègin dɔ̀nkili ìn kàn à bá yé , à\n",
      "9 yɛlɛmana kà kɛ́ wárabilen yé kà táa kúngo kɔ́nɔ . ò kɔ́ , dùgu mɔgɔw ye dɔ̀nkili ìn dá , ù bɛ́ɛ\n",
      "10 yɛlɛmana kà kɛ́ wárabilen yé kà táa kúngo kɔ́nɔ . ǹka , nê ma sɔ̀n kà à dá , ò dè y' à tó nê\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corp = Corpus('bam')\n",
    "results = corp.search('kɔ́nɔ', n_results = 10, subcorpus='corbama-net-tonal')\n",
    "for result in results:\n",
    "    for i,target in enumerate(result):\n",
    "        print(i+1,target.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To the top](#Documentation)\n",
    "\n",
    "#### [Maninka Automatically Parsed corpus](http://maslinsky.spb.ru/emk/run.cgi/first_form)\n",
    "##### Relevant parameters\n",
    "* **query**: str or list[str]: query or queries (currently only exact search by word or phrase is available)\n",
    "* **n_results**: int, default 100: number of results wanted\n",
    "* **kwic**: boolean, default True: `kwic` format (True) or a sentence (False)\n",
    "* **subcorpus**: str, default `cormani-brut-lat`: subcorpus. Available options: `cormani-brut-lat`, `corbama-brut-nko`\n",
    "* **writing_system**: str, default `None`: writing system for examples. Available options: `nko`, `latin`. Bug: only `latin` for `corbama-brut-nko` subcorpus.\n",
    "\n",
    "##### Example of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"tuma bɛɛ\": 100%|██████████| 10/10 [00:00<00:00, 39.06docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ߁߄ ߊߟߎ ߕߍߘߍ ߊߟߎ ߟߊߘߍߟߊ ߊߟߟߊ ߕߊߙߊ ߞߊ߲ߡߊ ߕߎߡߊ ߓߍ߯ .\n",
      "2 ‹ ߣ ߞߊ ߝߊ߯ߡߊ ߦߋ ߣ ߢߍ ߕߎߡߊ ߓߍ߯ .\n",
      "3 ߊߟߎ ߞߊ߲ ߞߏ : « ߗߍ ߣߌ߲ ߦߋ ߞߎߡߊ ߖߎ߯ ߝߐߟߊ ߦߐߙߐ ߛߊߣߌߡߊ߲ ߣߌ߲ ߡߊ ߕߎߡߊ ߓߍ߯ , ߞߊ ߞߎߡߊ ߖߎ߯ ߝߐ ߞߋߟߊ ߡߎߛߊ ߟߊ ߛߊߙߌߦߊ ߝߊߣߊ߲ ߡߊ .\n",
      "4 ߁ ߥߏ ߕߎߡߊ , ߛߐߟߌ ߕߍߘߍ ߝߊ߯ߡߊ ߌߛߊ ߟߊ ߞߊߙߊ߲ߘߋ߲ߣߎ ߟߊ ߢߊߣߊߡߊߦߊ ߡߊߛߌߟߊ߲ߣߊ ߕߎߡߊ ߓߍ߯ .\n",
      "5 ߡߏߛߏ ߥߏ ߕߍߘߍ ߞߏߢߎߡߊ ߞߍߟߊ ߕߎߡߊ ߓߍ߯ ߞߊ ߝߊ߲ߕߊ߲ߣߎ ߘߍߡߍ߲ .\n",
      "6 ߊ ߕߍߘߍ ߦߊߤߎߘߌߦߊ ߝߊ߲ߕߊ߲ߣߎ ߛߐߟߊ ߞߏߛߍߓߍ , ߞߊ ߊߟߟߊ ߕߊߙߊ ߕߎߡߊ ߓߍ߯ .\n",
      "7 ߁߇ ߞߐߣߌ߲ ߊ ߕߍߘߍ ߊ ߖߍߘߍ ߦߌߘߊߞߊߟߊ ߊߟߎ ߟߊ ߕߎߡߊ ߓߍ߯ ߊߟߊ ߞߋߥߊߟߌߢߎߡߊߟߎ ߝߍ .\n",
      "8 ߁߆ ߥߏ ߟߋ ߘߐ , ߣ ߦߋ ߣ ߘߐߖߊߟߊ ߕߎߡߊ ߓߍ߯ ߛߊ ߣ ߞߐߣߐߜߍߦߊߣߍ߲ ߘߌ ߕߏ .\n",
      "9 ߥߏ ߟߋ ߘߐ , ߊ ߕߍߘߍ ߔߐߟߌ ߞߌߟߌߟߊ ߕߎߡߊ ߓߍ߯ ߞߊ ߓߊߘߏ ߞߍ ߊ ߝߍ .\n",
      "10 ߂߉ ߣ ߦߋ ߊ ߝߍ ߟߋ ߖߎߛߎ ߥߏ ߢߐ߲߰ ߦߋ ߞߍ ߊߟߎ ߓߏߟߏ ߕߎߡߊ ߓߍ߯ ߞߊ ߛߌߟߊ߲ ߣ ߢߍ ߞߊ ߣߣߊ ߖߊߡߊߙߌߟߌߟߎ ߓߍ߯ ߟߊߕߋߟߋ߲ , ߛߊ ߊߟߎ ߣߌ ߊߟߎ ߞߐߡߐ߰ߟߎ ߓߍ߯ ߘߌ ߤߍߙߍ ߛߐߘߐ߲ ߞߊߘߊߥߎ .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corp = Corpus('emk')\n",
    "results = corp.search('tuma bɛɛ', n_results = 10, writing_system='nko', kwic=False)\n",
    "for result in results:\n",
    "    for i,target in enumerate(result):\n",
    "        print(i+1,target.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To the top](#Documentation)\n",
    "\n",
    "#### [National Corpus of Russian Language](http://ruscorpora.ru)\n",
    "##### Relevant parameters\n",
    "* **query**: str or list[str]: query or queries (currently only exact search by word or phrase is available)\n",
    "* **n_results**: int, default 100: number of results wanted\n",
    "* **kwic**: boolean, default True: `kwic` format (True) or a sentence (False)\n",
    "* **get_analysis**: boolean, default False: whether to collect grammatical tags for target word or not\n",
    "* **subcorpus**: str, default `main`: subcorpus. Available options:`main`, `syntax`, `paper`, `regional`, `school`, `dialect`, `poetic`, `spoken`, `accent`, `murco`, `multiparc`, `old_rus`, `birchbark`, `mid_rus`, `orthlib`.\n",
    "\n",
    "##### Example of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"сердце\": 100%|██████████| 10/10 [00:04<00:00,  2.11docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   Не будильник поставлен на шесть,  а колотится сердце быстрей. \n",
      "2   Да и сердце легче бьется ― поддается уговорам. \n",
      "3   Прелесть, от нее дрожит сердце возле птиц или ночниц бледных. \n",
      "4   Чтоб они стали перинами белыми с мягкой опорой на дне,  и невредимыми съехали, целыми дети на той стороне.   Сердце привязано ниткой невидимой.   Нить коротка, а земля велика. \n",
      "5   Моя мама умерла девятого мая, когда всюду день-деньской надрывают сердце «аты-баты» ― коллективный катарсис такой. \n",
      "6  Чтобы скорей, скорей горло его достать.   Сердце его потрогать. \n",
      "7   И ― прочь через площадь в закатных лучах В какой-нибудь Чехии, Польше… Разбитое сердце, своя голова на плечах ― Чего тебе больше? \n",
      "8   «Хотел бы я знать, если Бог повелит,  О чем твое старое сердце болит». \n",
      "9   Когда уйдет последний друг И в сердце перемрут подруги,  Я очерчу незримый круг И лиру заключу в том круге. \n",
      "10   О том не надо вспоминать,  Но что-то в сердце изломилось:  ― Не узнаю родную мать. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corp = Corpus('rus')\n",
    "results = corp.search('сердце', n_results = 10, subcorpus='poetic')\n",
    "for result in results:\n",
    "    for i, target in enumerate(result):\n",
    "        print(i+1, target.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To the top](#Documentation)\n",
    "\n",
    "#### [Parallel subcorpus of National Corpus of Russian Language](http://ruscorpora.ru/search-para-multi.html)\n",
    "##### Relevant parameters\n",
    "* **query**: str or list[str]: query or queries (currently only exact search by word or phrase is available)\n",
    "* **query_language**: str: language of the query\n",
    "* **n_results**: int, default 100: number of results wanted\n",
    "* **kwic**: boolean, default True: `kwic` format (True) or a sentence (False)\n",
    "* **get_analysis**: boolean, default False: whether to collect grammatical tags for target word or not\n",
    "* **subcorpus**: str, default `rus` (search by all target languages): subcorpus. Available options: `rus`, `eng`, `bel`, `bul`, `bua`, `esp`, `ita`,`zho`, `lav`, `ger`, `pol`, `ukr`, `fra`, `sve`, `est`.\n",
    "\n",
    "##### Example of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"авось\": 100%|██████████| 10/10 [00:04<00:00,  2.28docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fr \n",
      " – Русский человек крепок на трех сваях – «авось», «небось» и «как-нибудь».\n",
      "2 bg \n",
      " – Я признаться уж не верю-с… – Порфирий Петрович махнул рукой. – Ничего мы тут не зацепим. Кругом одна безнадежность… А впрочем сходите.    Авось вам больше моего повезет.    И ведь как в воду смотрел.\n",
      "3 bg \n",
      " Русский злодей горяч и нерасчетлив, крушит на авось.\n",
      "4 bg \n",
      " Во-первых, преступление все-таки оказалось не европейское, а русское, на авось.\n",
      "5 bg \n",
      " Да еще нумер каждому проставьте.    Ничего, авось не перепутаем-с.    Я их всех уж наизусть успел выучить.\n",
      "6 pl \n",
      " Никто, естественно, не запретит вашей милости кропать новые эпистолы, ибо капля камень точит, как знать, авось кто-нибудь из кардиналов наконец поддастся, возможно, меня наконец отзовут.\n",
      "7 be \n",
      " Положение его, конечно, аховое, но в глубине сознания все-таки теплилась маленькая надежда.    На авось или, может, на чудо.    Когда другого не находилось, обычно полагались на чудо, так было всегда.\n",
      "8 be \n",
      " Положение его, конечно, аховое, но в глубине сознания все-таки теплилась маленькая надежда.    На авось или, может, на чудо.    Когда другого не находилось, обычно полагались на чудо, так было всегда.\n",
      "9 be \n",
      " Чудо, конечно, выручало редко, больше подводило, особенно атеистов-большевиков, которые теперь так дружно стали взывать к христианскому чуду.    Авось выручит!    ―\n",
      "10 be \n",
      " Чудо, конечно, выручало редко, больше подводило, особенно атеистов-большевиков, которые теперь так дружно стали взывать к христианскому чуду.    Авось выручит!    ―\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corp = Corpus('rus_parallel')\n",
    "results = corp.search('авось', query_language='rus', n_results = 10)\n",
    "for result in results:\n",
    "    for i,target in enumerate(result):\n",
    "        print(i+1,target.transl.strip(),'\\n',target.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To the top](#Documentation)\n",
    "\n",
    "#### [Center of Chinese Linguistics corpus](http://ccl.pku.edu.cn:8080/ccl_corpus/index.jsp) \n",
    "##### Relevant parameters\n",
    "* **query**: str or list[str]: query or queries (currently only exact search by word or phrase is available)\n",
    "* **n_results**: int, default 100: number of results wanted\n",
    "* **subcorpus**: str, default `xiandai`: subcorpus. Available options: `xiandai` (modern Chinese) or `dugai` (ancient Chinese).\n",
    "* **n_left**, **n_right**: int, default 30: context lenght (in symbols)\n",
    "\n",
    "##### Example of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"能力#3大\": 100%|██████████| 10/10 [00:01<00:00,  6.03docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ...的人生方向。每年韩国高考--\"大学修业能力考试\"举行当日，所有的公务员和私...\n",
      "2 ...学生的品德如何、修养怎样、生存能力大小、自立能力强弱等这些关系孩子生...\n",
      "3 ...索引擎从网络中获取信息的动力和能力；大学前的教育大多是在以教师为中心、...\n",
      "4 ...的信息化社会中，处理非确定信息能力的大小将会成为衡量一个教师作用大小的...\n",
      "5 ...，法国中、小学生识字和拼写法文能力大幅度下降。在一项对15岁学生法文...\n",
      "6 ...公司的股东能决定要如何使用生产能力。在更大的公司里，公司的权力架构通常有一...\n",
      "7 ...如某些弹性纤维就具有弹力(变形能力)大、屈光好、韧度高以及抗酸碱侵蚀性...\n",
      "8 ...缩小,导致国家对整个社会的控制能力大大降低。例如，在SARS防治需要...\n",
      "9 ...六，七岁）。幼儿的再认识和回忆能力有很大发展，回忆范围逐渐扩大了。其特点...\n",
      "10 ...来，拍起马来，比哪一个国家的人能力都大。因之这里所谓“私”的问题却是个...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corp = Corpus('zho')\n",
    "results = corp.search('能力#3大', n_results = 10, n_left=15, n_right=15)\n",
    "for result in results:\n",
    "    for i,target in enumerate(result):\n",
    "        print(i+1,target.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To the top](#Documentation)\n",
    "\n",
    "## Working with results\n",
    "\n",
    "### lingcorpora.Result\n",
    "\n",
    "The object of this class contains all results found. `Result` object is iterable and supports indexing.\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "* **results**: list[`Target`]: list of results\n",
    "* **N**: int: number of results\n",
    "* **lang**: str: corpus language\n",
    "* **query**: str: search query\n",
    "* **params**: dict: all other parameters of the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"tuma\": 100%|██████████| 10/10 [00:00<00:00, 39.82docs/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(query=tuma, N=10, params={'n_results': 10, 'kwic': False, 'n_left': None, 'n_right': None, 'query_language': None, 'subcorpus': 'cormani-brut-lat', 'get_analysis': False, 'gr_tags': None, 'start': 0, 'writing_system': ''})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp = Corpus('emk')\n",
    "results = corp.search('tuma', n_results = 10, kwic=False)[0]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lingcorpora.Result.export_csv(filename=None, header=True, sep=';')\n",
    "\n",
    "Writes results into a `csv` file considering `kwic` parameter of the search.\n",
    "\n",
    "##### Arguments\n",
    "* **filename**: str, optional, default `None`: name of the file. If `None`, filename is *lang*_*query*_results.csv with omission of disallowed filename symbols\n",
    "* **header**: boolean, optional, default True: whether to include a header in the table\n",
    "* **sep**: str, optional, default `;`: cell separator in the csv\n",
    "\n",
    "##### Output\n",
    "None, writes results into the file.\n",
    "\n",
    "#### lingcorpora.Result.clear()\n",
    "\n",
    "Overwrites the `results` attribute to empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Target(tuma, ), Target(tuma, ), Target(tuma, ), Target(tuma, ), Target(tuma, ), Target(tuma, ), Target(tuma, ), Target(tuma, ), Target(tuma, ), Target(tuma, )]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(results.results)\n",
    "results.clear()\n",
    "print(results.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To the top](#Documentation)\n",
    "\n",
    "### lingcorpora.Target\n",
    "\n",
    "`Target` contains one item from the result list.\n",
    "\n",
    "#### Attributes\n",
    "* **text**: str: full example (sentence or `kwic`)\n",
    "* **idxs**: idxs: tuple (l, r): target indices in **text** -> text[l:r]\n",
    "* **meta**: str: sentence / document metadata, e.g. document name, author, etc. (if exists)\n",
    "* **tags**: dict: target tags\n",
    "* **transl**: str: text translation (only for parallel corpora)\n",
    "* **lang**: str: translation language (only for parallel corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"одеяло\": 100%|██████████| 10/10 [00:04<00:00,  2.30docs/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Target(одеяло, Народный костюм: архаика или современность? // «Народное творчество», 2004)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus_corp = Corpus('rus')\n",
    "rus_results = rus_corp.search('одеяло', n_results = 10, get_analysis=True)[0]\n",
    "first_hit = rus_results[0]\n",
    "first_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text  Я, например, для внучки настегала своими руками лоскутное одеяло, зная, что оно будет её оберегать, давать ей энергию. \n",
      "idxs (59, 65)\n",
      "meta Народный костюм: архаика или современность? // «Народное творчество», 2004\n",
      "analysis {'lex': ['одеяло'], 'gramm': ['S', 'inan', 'n', 'sg', 'acc', 'disamb'], 'sem': ['r:concr', 't:tool:bedding'], 'flags': ['animred', 'bcomma', 'bmark', 'casered', 'genderred', 'numred']}\n",
      "gr_tags None\n",
      "transl None\n",
      "lang None\n"
     ]
    }
   ],
   "source": [
    "for k,v in vars(first_hit).items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lingcorpora.Target.kwic(left, right, level='word')\n",
    "\n",
    "This function makes `kwic` format for an item for further usage and csv output.\n",
    "\n",
    "##### Attributes\n",
    "* **left**: int: length of left context\n",
    "* **right**: int: length of right context\n",
    "* **level**: str, optional, default `word`: counting context length by tokens (`word`) or by characters (`char`)\n",
    "\n",
    "##### Output\n",
    "tuple: (left context, target, right context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('внучки настегала своими руками лоскутное', 'одеяло', ', зная, что оно будет её')\n",
      "('егала своими руками лоскутное ', 'одеяло', ', зная, что оно будет её обере')\n"
     ]
    }
   ],
   "source": [
    "print(first_hit.kwic(left=5,right=5))\n",
    "print(first_hit.kwic(left=30,right=30, level='char'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To the top](#Documentation)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
